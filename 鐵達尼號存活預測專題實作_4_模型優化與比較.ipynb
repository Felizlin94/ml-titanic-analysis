{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPPECOsUO+TMbz2WP1WaajM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Felizlin94/ml-titanic-analysis/blob/main/%E9%90%B5%E9%81%94%E5%B0%BC%E8%99%9F%E5%AD%98%E6%B4%BB%E9%A0%90%E6%B8%AC%E5%B0%88%E9%A1%8C%E5%AF%A6%E4%BD%9C_4_%E6%A8%A1%E5%9E%8B%E5%84%AA%E5%8C%96%E8%88%87%E6%AF%94%E8%BC%83.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igqRoWBv6qWg",
        "outputId": "d3123090-c0df-4f70-ad52-4b49c18daffa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running GridSearchCV for Logistic Regression\n",
            "Logistic Regression Best Score: 0.7980\n",
            "Best Parameters: {'C': 10, 'solver': 'liblinear'}\n",
            "\n",
            "Running GridSearchCV for SVM\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import xgboost as xgb\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/dsindy/kaggle-titanic/master/data/train.csv')\n",
        "\n",
        "# Feature Processing\n",
        "df['Cabin_Category'] = df['Cabin'].str[0]\n",
        "df['Family_Size'] = df['SibSp'] + df['Parch'] + 1\n",
        "df.drop(['Name', 'Ticket', 'PassengerId', 'Cabin', 'SibSp', 'Parch'], axis=1, inplace=True)\n",
        "df['Age'].fillna(df['Age'].median(), inplace=True)\n",
        "df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)\n",
        "df['Cabin_Category'].fillna('Unknown', inplace=True)\n",
        "df = pd.get_dummies(df, columns=['Sex', 'Embarked', 'Cabin_Category'], dtype=int)\n",
        "\n",
        "# Define models\n",
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(random_state=0, max_iter=5000),\n",
        "    'SVM': SVC(random_state=0),\n",
        "    'Random Forest': RandomForestClassifier(random_state=0),\n",
        "    'KNN': KNeighborsClassifier(),\n",
        "    'Naive Bayes': GaussianNB(),\n",
        "    'LDA': LinearDiscriminantAnalysis()\n",
        "}\n",
        "\n",
        "df_train = df\n",
        "columns_X = list(set(df.columns) - {'Survived'})\n",
        "columns_y = ['Survived']\n",
        "train_X = df_train[columns_X]\n",
        "train_y = df_train[columns_y]\n",
        "\n",
        "# Define parameter grids\n",
        "param_grids = {\n",
        "    'Logistic Regression': {\n",
        "        'C': [0.01, 0.1, 1, 10, 100],\n",
        "        'solver': ['lbfgs', 'liblinear', 'saga']\n",
        "    },\n",
        "    'SVM': {\n",
        "        'C': [0.1, 1, 10, 100],\n",
        "        'kernel': ['linear', 'poly', 'rbf', 'sigmoid']\n",
        "    },\n",
        "    'Random Forest': {\n",
        "        'n_estimators': [10, 50, 100, 200],\n",
        "        'max_depth': [None, 10, 20, 30]\n",
        "    },\n",
        "    'KNN': {\n",
        "        'n_neighbors': [3, 5, 7, 9],\n",
        "        'weights': ['uniform', 'distance']\n",
        "    },\n",
        "    'Naive Bayes': {\n",
        "        'var_smoothing': np.logspace(-9, 0, 10)\n",
        "    },\n",
        "    'LDA': {\n",
        "        'solver': ['svd', 'lsqr', 'eigen']\n",
        "    }\n",
        "}\n",
        "\n",
        "# Apply GridSearchCV and evaluate\n",
        "results = {}\n",
        "for model_name, model in models.items():\n",
        "    print(f\"\\nRunning GridSearchCV for {model_name}\")\n",
        "    grid = GridSearchCV(model, param_grids[model_name], cv=5, scoring='accuracy')\n",
        "    grid.fit(train_X, train_y.values.ravel())\n",
        "    best_model = grid.best_estimator_\n",
        "    best_score = grid.best_score_\n",
        "    best_params = grid.best_params_\n",
        "    results[model_name] = {'best_score': best_score, 'best_params': best_params}\n",
        "    print(f\"{model_name} Best Score: {best_score:.4f}\")\n",
        "    print(f\"Best Parameters: {best_params}\")\n",
        "\n",
        "# TensorFlow Model\n",
        "tf_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100, activation='relu', input_shape=(train_X.shape[1],)),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "tf_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "tf_model.fit(train_X, train_y, epochs=100, batch_size=32, verbose=0)\n",
        "tf_best_score = tf_model.evaluate(train_X, train_y, verbose=0)[1]\n",
        "results['TensorFlow'] = {'best_score': tf_best_score}\n",
        "print(f\"TensorFlow Best Score: {tf_best_score:.4f}\")\n",
        "\n",
        "# PyTorch Model\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(train_X.shape[1], 100)\n",
        "        self.fc2 = nn.Linear(100, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.sigmoid(self.fc2(x))\n",
        "        return x\n",
        "\n",
        "X_tensor = torch.tensor(train_X.values, dtype=torch.float32)\n",
        "y_tensor = torch.tensor(train_y.values, dtype=torch.float32)\n",
        "dataset = TensorDataset(X_tensor, y_tensor)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "pytorch_model = SimpleNN()\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(pytorch_model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(100):\n",
        "    for batch_X, batch_y in dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = pytorch_model(batch_X)\n",
        "        loss = criterion(outputs, batch_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "pytorch_model.eval()\n",
        "with torch.no_grad():\n",
        "    pytorch_best_score = ((pytorch_model(X_tensor).numpy().flatten() > 0.5) == train_y.values.flatten()).mean()\n",
        "results['PyTorch'] = {'best_score': pytorch_best_score}\n",
        "print(f\"PyTorch Best Score: {pytorch_best_score:.4f}\")\n",
        "\n",
        "# XGBoost Model\n",
        "dtrain = xgb.DMatrix(train_X, label=train_y)\n",
        "param_grid = {\n",
        "    'max_depth': [3, 4, 5],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'n_estimators': [100, 200, 300]\n",
        "}\n",
        "xgb_model = xgb.XGBClassifier()\n",
        "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(train_X, train_y.values.ravel())\n",
        "xgb_best_model = grid_search.best_estimator_\n",
        "xgb_best_score = grid_search.best_score_\n",
        "xgb_best_params = grid_search.best_params_\n",
        "results['XGBoost'] = {'best_score': xgb_best_score, 'best_params': xgb_best_params}\n",
        "print(f\"XGBoost Best Score: {xgb_best_score:.4f}\")\n",
        "print(f\"Best Parameters: {xgb_best_params}\")\n",
        "\n",
        "# Print all results\n",
        "df_results = pd.DataFrame(results).T.reset_index()\n",
        "df_results.columns = ['Model', 'Best Score', 'Best Parameters']\n",
        "df_results = df_results.sort_values(by='Best Score', ascending=False).reset_index(drop=True)\n",
        "df_results['Rank'] = df_results.index + 1\n",
        "print(\"\\nResults Summary:\")\n",
        "print(df_results)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oXoh5KgdTpyF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}