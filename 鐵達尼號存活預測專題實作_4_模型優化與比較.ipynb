{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPPECOsUO+TMbz2WP1WaajM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Felizlin94/ml-titanic-analysis/blob/main/%E9%90%B5%E9%81%94%E5%B0%BC%E8%99%9F%E5%AD%98%E6%B4%BB%E9%A0%90%E6%B8%AC%E5%B0%88%E9%A1%8C%E5%AF%A6%E4%BD%9C_4_%E6%A8%A1%E5%9E%8B%E5%84%AA%E5%8C%96%E8%88%87%E6%AF%94%E8%BC%83.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igqRoWBv6qWg",
        "outputId": "d3123090-c0df-4f70-ad52-4b49c18daffa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running GridSearchCV for Logistic Regression\n",
            "Logistic Regression Best Score: 0.7980\n",
            "Best Parameters: {'C': 10, 'solver': 'liblinear'}\n",
            "\n",
            "Running GridSearchCV for SVM\n",
            "SVM Best Score: 0.7867\n",
            "Best Parameters: {'C': 1, 'kernel': 'linear'}\n",
            "\n",
            "Running GridSearchCV for Random Forest\n",
            "Random Forest Best Score: 0.8272\n",
            "Best Parameters: {'max_depth': 10, 'n_estimators': 50}\n",
            "\n",
            "Running GridSearchCV for KNN\n",
            "KNN Best Score: 0.7240\n",
            "Best Parameters: {'n_neighbors': 7, 'weights': 'distance'}\n",
            "\n",
            "Running GridSearchCV for Naive Bayes\n",
            "Naive Bayes Best Score: 0.7621\n",
            "Best Parameters: {'var_smoothing': 1e-09}\n",
            "\n",
            "Running GridSearchCV for LDA\n",
            "LDA Best Score: 0.7969\n",
            "Best Parameters: {'solver': 'svd'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "5 fits failed out of a total of 15.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py\", line 631, in fit\n",
            "    self._solve_eigen(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py\", line 463, in _solve_eigen\n",
            "    evals, evecs = linalg.eigh(Sb, Sw)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/scipy/linalg/_decomp.py\", line 593, in eigh\n",
            "    raise LinAlgError('The leading minor of order {} of B is not '\n",
            "numpy.linalg.LinAlgError: The leading minor of order 17 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py\", line 631, in fit\n",
            "    self._solve_eigen(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py\", line 463, in _solve_eigen\n",
            "    evals, evecs = linalg.eigh(Sb, Sw)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/scipy/linalg/_decomp.py\", line 593, in eigh\n",
            "    raise LinAlgError('The leading minor of order {} of B is not '\n",
            "numpy.linalg.LinAlgError: The leading minor of order 11 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "3 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py\", line 631, in fit\n",
            "    self._solve_eigen(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/discriminant_analysis.py\", line 463, in _solve_eigen\n",
            "    evals, evecs = linalg.eigh(Sb, Sw)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/scipy/linalg/_decomp.py\", line 593, in eigh\n",
            "    raise LinAlgError('The leading minor of order {} of B is not '\n",
            "numpy.linalg.LinAlgError: The leading minor of order 14 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.79686774 0.79686774        nan]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow Best Score: 0.8294\n",
            "PyTorch Best Score: 0.8283\n",
            "XGBoost Best Score: 0.8373\n",
            "Best Parameters: {'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 100}\n",
            "\n",
            "Results Summary:\n",
            "                 Model Best Score  \\\n",
            "0              XGBoost   0.837292   \n",
            "1           TensorFlow   0.829405   \n",
            "2              PyTorch   0.828283   \n",
            "3        Random Forest   0.827155   \n",
            "4  Logistic Regression   0.797998   \n",
            "5                  LDA   0.796868   \n",
            "6                  SVM   0.786749   \n",
            "7          Naive Bayes   0.762074   \n",
            "8                  KNN    0.72396   \n",
            "\n",
            "                                     Best Parameters  Rank  \n",
            "0  {'learning_rate': 0.1, 'max_depth': 4, 'n_esti...     1  \n",
            "1                                                NaN     2  \n",
            "2                                                NaN     3  \n",
            "3              {'max_depth': 10, 'n_estimators': 50}     4  \n",
            "4                   {'C': 10, 'solver': 'liblinear'}     5  \n",
            "5                                  {'solver': 'svd'}     6  \n",
            "6                       {'C': 1, 'kernel': 'linear'}     7  \n",
            "7                           {'var_smoothing': 1e-09}     8  \n",
            "8          {'n_neighbors': 7, 'weights': 'distance'}     9  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import xgboost as xgb\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/dsindy/kaggle-titanic/master/data/train.csv')\n",
        "\n",
        "# Feature Processing\n",
        "df['Cabin_Category'] = df['Cabin'].str[0]\n",
        "df['Family_Size'] = df['SibSp'] + df['Parch'] + 1\n",
        "df.drop(['Name', 'Ticket', 'PassengerId', 'Cabin', 'SibSp', 'Parch'], axis=1, inplace=True)\n",
        "df['Age'].fillna(df['Age'].median(), inplace=True)\n",
        "df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)\n",
        "df['Cabin_Category'].fillna('Unknown', inplace=True)\n",
        "df = pd.get_dummies(df, columns=['Sex', 'Embarked', 'Cabin_Category'], dtype=int)\n",
        "\n",
        "# Define models\n",
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(random_state=0, max_iter=5000),\n",
        "    'SVM': SVC(random_state=0),\n",
        "    'Random Forest': RandomForestClassifier(random_state=0),\n",
        "    'KNN': KNeighborsClassifier(),\n",
        "    'Naive Bayes': GaussianNB(),\n",
        "    'LDA': LinearDiscriminantAnalysis()\n",
        "}\n",
        "\n",
        "df_train = df\n",
        "columns_X = list(set(df.columns) - {'Survived'})\n",
        "columns_y = ['Survived']\n",
        "train_X = df_train[columns_X]\n",
        "train_y = df_train[columns_y]\n",
        "\n",
        "# Define parameter grids\n",
        "param_grids = {\n",
        "    'Logistic Regression': {\n",
        "        'C': [0.01, 0.1, 1, 10, 100],\n",
        "        'solver': ['lbfgs', 'liblinear', 'saga']\n",
        "    },\n",
        "    'SVM': {\n",
        "        'C': [0.1, 1, 10, 100],\n",
        "        'kernel': ['linear', 'poly', 'rbf', 'sigmoid']\n",
        "    },\n",
        "    'Random Forest': {\n",
        "        'n_estimators': [10, 50, 100, 200],\n",
        "        'max_depth': [None, 10, 20, 30]\n",
        "    },\n",
        "    'KNN': {\n",
        "        'n_neighbors': [3, 5, 7, 9],\n",
        "        'weights': ['uniform', 'distance']\n",
        "    },\n",
        "    'Naive Bayes': {\n",
        "        'var_smoothing': np.logspace(-9, 0, 10)\n",
        "    },\n",
        "    'LDA': {\n",
        "        'solver': ['svd', 'lsqr', 'eigen']\n",
        "    }\n",
        "}\n",
        "\n",
        "# Apply GridSearchCV and evaluate\n",
        "results = {}\n",
        "for model_name, model in models.items():\n",
        "    print(f\"\\nRunning GridSearchCV for {model_name}\")\n",
        "    grid = GridSearchCV(model, param_grids[model_name], cv=5, scoring='accuracy')\n",
        "    grid.fit(train_X, train_y.values.ravel())\n",
        "    best_model = grid.best_estimator_\n",
        "    best_score = grid.best_score_\n",
        "    best_params = grid.best_params_\n",
        "    results[model_name] = {'best_score': best_score, 'best_params': best_params}\n",
        "    print(f\"{model_name} Best Score: {best_score:.4f}\")\n",
        "    print(f\"Best Parameters: {best_params}\")\n",
        "\n",
        "# TensorFlow Model\n",
        "tf_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(100, activation='relu', input_shape=(train_X.shape[1],)),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "tf_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "tf_model.fit(train_X, train_y, epochs=100, batch_size=32, verbose=0)\n",
        "tf_best_score = tf_model.evaluate(train_X, train_y, verbose=0)[1]\n",
        "results['TensorFlow'] = {'best_score': tf_best_score}\n",
        "print(f\"TensorFlow Best Score: {tf_best_score:.4f}\")\n",
        "\n",
        "# PyTorch Model\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(train_X.shape[1], 100)\n",
        "        self.fc2 = nn.Linear(100, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.sigmoid(self.fc2(x))\n",
        "        return x\n",
        "\n",
        "X_tensor = torch.tensor(train_X.values, dtype=torch.float32)\n",
        "y_tensor = torch.tensor(train_y.values, dtype=torch.float32)\n",
        "dataset = TensorDataset(X_tensor, y_tensor)\n",
        "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "pytorch_model = SimpleNN()\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(pytorch_model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(100):\n",
        "    for batch_X, batch_y in dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = pytorch_model(batch_X)\n",
        "        loss = criterion(outputs, batch_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "pytorch_model.eval()\n",
        "with torch.no_grad():\n",
        "    pytorch_best_score = ((pytorch_model(X_tensor).numpy().flatten() > 0.5) == train_y.values.flatten()).mean()\n",
        "results['PyTorch'] = {'best_score': pytorch_best_score}\n",
        "print(f\"PyTorch Best Score: {pytorch_best_score:.4f}\")\n",
        "\n",
        "# XGBoost Model\n",
        "dtrain = xgb.DMatrix(train_X, label=train_y)\n",
        "param_grid = {\n",
        "    'max_depth': [3, 4, 5],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'n_estimators': [100, 200, 300]\n",
        "}\n",
        "xgb_model = xgb.XGBClassifier()\n",
        "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(train_X, train_y.values.ravel())\n",
        "xgb_best_model = grid_search.best_estimator_\n",
        "xgb_best_score = grid_search.best_score_\n",
        "xgb_best_params = grid_search.best_params_\n",
        "results['XGBoost'] = {'best_score': xgb_best_score, 'best_params': xgb_best_params}\n",
        "print(f\"XGBoost Best Score: {xgb_best_score:.4f}\")\n",
        "print(f\"Best Parameters: {xgb_best_params}\")\n",
        "\n",
        "# Print all results\n",
        "df_results = pd.DataFrame(results).T.reset_index()\n",
        "df_results.columns = ['Model', 'Best Score', 'Best Parameters']\n",
        "df_results = df_results.sort_values(by='Best Score', ascending=False).reset_index(drop=True)\n",
        "df_results['Rank'] = df_results.index + 1\n",
        "print(\"\\nResults Summary:\")\n",
        "print(df_results)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oXoh5KgdTpyF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}